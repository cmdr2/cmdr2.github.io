---
title: "Post from Dec 05, 2024"
date: 2024-12-05T16:34:30
slug: "1733416470"
tags:
  - ml
  - transformers
  - diffusion
---

Spent a few days learning more about Diffusion models, UNets and Transformers. Wrote a few [toy implementations](https://github.com/cmdr2/study/tree/main/ml) of a denoising diffusion model (following [diffusers' tutorial](https://huggingface.co/docs/diffusers/en/tutorials/basic_training)) and a simple multi-headed self-attention model for next-character prediction (following [Karpathy's video](https://www.youtube.com/watch?v=kCc8FmEb1nY)).

The non-latent version of the denoising model was trained on the [Smithsonian Butterfly dataset](https://huggingface.co/datasets/huggan/smithsonian_butterflies_subset), and it successfully generates new butterfly images. But it's unconditional (i.e. no text prompts), and non-latent (i.e. works directly on the image data, instead of a compressed latent space).

The latent version doesn't seem to be working correctly right now. It runs, but the output is garbage, and I don't think it's training correctly. I pre-converted the entire butterfly dataset into latent encodings before training (to speed up training), but the results were garbage even if I did the VAE encoding during training. Still need to look into this more.

The multi-headed self-attention implementation is structurally okay (I think), but I think it's too simple to learn anything meaningful about sentence structures. I might be wrong, since I'm a newbie. I haven't implemented the rest of the transformer architecture, since I was just trying to get some intuition around the attention mechanism.

The purpose of this deep-dive was to develop better intuition about how the models work, and where the runtime performance and memory hotspots are (in these models).